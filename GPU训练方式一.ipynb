{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "训练数据集的长度为: 50000\n",
      "测试数据集的长度为: 10000\n",
      "--------第1次训练--------\n",
      "用时为2.9783527851104736\n",
      "训练次数：100，Loss:2.2871689796447754\n",
      "用时为5.569734573364258\n",
      "训练次数：200，Loss:2.2847232818603516\n",
      "用时为8.717462539672852\n",
      "训练次数：300，Loss:2.243137836456299\n",
      "用时为12.77467966079712\n",
      "训练次数：400，Loss:2.1485440731048584\n",
      "用时为15.718845844268799\n",
      "训练次数：500，Loss:2.0485920906066895\n",
      "用时为18.666834354400635\n",
      "训练次数：600，Loss:2.054527759552002\n",
      "用时为21.419596672058105\n",
      "训练次数：700，Loss:1.9580562114715576\n",
      "整体的测试损失: 307.648197054863\n",
      "--------第2次训练--------\n",
      "用时为27.102738618850708\n",
      "训练次数：800，Loss:1.8447058200836182\n",
      "用时为29.78717279434204\n",
      "训练次数：900，Loss:1.8067423105239868\n",
      "用时为32.774945974349976\n",
      "训练次数：1000，Loss:1.904280185699463\n",
      "用时为35.50830078125\n",
      "训练次数：1100，Loss:1.974926471710205\n",
      "用时为38.29217529296875\n",
      "训练次数：1200，Loss:1.68411123752594\n",
      "用时为41.075289726257324\n",
      "训练次数：1300，Loss:1.6247830390930176\n",
      "用时为43.712875843048096\n",
      "训练次数：1400，Loss:1.7058930397033691\n",
      "用时为46.72891426086426\n",
      "训练次数：1500，Loss:1.7766233682632446\n",
      "整体的测试损失: 287.59297466278076\n",
      "--------第3次训练--------\n",
      "用时为51.73811459541321\n",
      "训练次数：1600，Loss:1.7170753479003906\n",
      "用时为54.47895884513855\n",
      "训练次数：1700，Loss:1.6482057571411133\n",
      "用时为57.42661380767822\n",
      "训练次数：1800，Loss:1.9292187690734863\n",
      "用时为60.24060916900635\n",
      "训练次数：1900，Loss:1.6991405487060547\n",
      "用时为63.41788935661316\n",
      "训练次数：2000，Loss:1.870530366897583\n",
      "用时为66.14775466918945\n",
      "训练次数：2100，Loss:1.5042235851287842\n",
      "用时为69.33372092247009\n",
      "训练次数：2200，Loss:1.4902377128601074\n",
      "用时为72.28994393348694\n",
      "训练次数：2300，Loss:1.7680244445800781\n",
      "整体的测试损失: 261.527903676033\n",
      "--------第4次训练--------\n",
      "用时为77.36177515983582\n",
      "训练次数：2400，Loss:1.7122608423233032\n",
      "用时为80.2337396144867\n",
      "训练次数：2500，Loss:1.3437567949295044\n",
      "用时为83.33514833450317\n",
      "训练次数：2600，Loss:1.5882902145385742\n",
      "用时为86.85744404792786\n",
      "训练次数：2700，Loss:1.666356086730957\n",
      "用时为91.13406753540039\n",
      "训练次数：2800，Loss:1.4915579557418823\n",
      "用时为95.31519603729248\n",
      "训练次数：2900，Loss:1.6357605457305908\n",
      "用时为99.6484944820404\n",
      "训练次数：3000，Loss:1.3557292222976685\n",
      "用时为103.8800196647644\n",
      "训练次数：3100，Loss:1.4907615184783936\n",
      "整体的测试损失: 265.4975279569626\n",
      "--------第5次训练--------\n",
      "用时为111.8584656715393\n",
      "训练次数：3200，Loss:1.359643578529358\n",
      "用时为116.05207228660583\n",
      "训练次数：3300，Loss:1.4798235893249512\n",
      "用时为120.04504942893982\n",
      "训练次数：3400，Loss:1.4696307182312012\n",
      "用时为124.38087129592896\n",
      "训练次数：3500，Loss:1.5138437747955322\n",
      "用时为128.74519896507263\n",
      "训练次数：3600，Loss:1.5880699157714844\n",
      "用时为132.91195631027222\n",
      "训练次数：3700，Loss:1.3206294775009155\n",
      "用时为137.21623158454895\n",
      "训练次数：3800，Loss:1.250461459159851\n",
      "用时为141.437655210495\n",
      "训练次数：3900，Loss:1.455727219581604\n",
      "整体的测试损失: 257.08955335617065\n",
      "--------第6次训练--------\n",
      "用时为149.32046914100647\n",
      "训练次数：4000，Loss:1.4111171960830688\n",
      "用时为153.7679796218872\n",
      "训练次数：4100，Loss:1.4642059803009033\n",
      "用时为158.10482335090637\n",
      "训练次数：4200，Loss:1.527791142463684\n",
      "用时为162.29027652740479\n",
      "训练次数：4300，Loss:1.1905438899993896\n",
      "用时为166.43821954727173\n",
      "训练次数：4400，Loss:1.1364412307739258\n",
      "用时为170.74588179588318\n",
      "训练次数：4500，Loss:1.35890531539917\n",
      "用时为175.1923122406006\n",
      "训练次数：4600，Loss:1.4104588031768799\n",
      "整体的测试损失: 245.2315011024475\n",
      "--------第7次训练--------\n",
      "用时为183.0349416732788\n",
      "训练次数：4700，Loss:1.3374525308609009\n",
      "用时为187.48364162445068\n",
      "训练次数：4800，Loss:1.5228285789489746\n",
      "用时为191.83643102645874\n",
      "训练次数：4900，Loss:1.3739315271377563\n",
      "用时为195.94732761383057\n",
      "训练次数：5000，Loss:1.4150850772857666\n",
      "用时为200.23794960975647\n",
      "训练次数：5100，Loss:0.9951307773590088\n",
      "用时为204.46655583381653\n",
      "训练次数：5200，Loss:1.2786340713500977\n",
      "用时为208.78813362121582\n",
      "训练次数：5300，Loss:1.201174259185791\n",
      "用时为213.082337141037\n",
      "训练次数：5400，Loss:1.3373186588287354\n",
      "整体的测试损失: 236.16734838485718\n",
      "--------第8次训练--------\n",
      "用时为220.93585062026978\n",
      "训练次数：5500，Loss:1.2477717399597168\n",
      "用时为225.33853101730347\n",
      "训练次数：5600，Loss:1.2167937755584717\n",
      "用时为229.4359679222107\n",
      "训练次数：5700，Loss:1.1985021829605103\n",
      "用时为233.75979924201965\n",
      "训练次数：5800，Loss:1.229195475578308\n",
      "用时为237.97444868087769\n",
      "训练次数：5900，Loss:1.3182392120361328\n",
      "用时为242.24662399291992\n",
      "训练次数：6000，Loss:1.5330898761749268\n",
      "用时为246.67592191696167\n",
      "训练次数：6100，Loss:1.0692507028579712\n",
      "用时为250.97660636901855\n",
      "训练次数：6200，Loss:1.1158429384231567\n",
      "整体的测试损失: 225.42085230350494\n",
      "--------第9次训练--------\n",
      "用时为258.94723749160767\n",
      "训练次数：6300，Loss:1.3780364990234375\n",
      "用时为263.452036857605\n",
      "训练次数：6400，Loss:1.146417260169983\n",
      "用时为268.90197229385376\n",
      "训练次数：6500，Loss:1.5519706010818481\n",
      "用时为673.8894662857056\n",
      "训练次数：6600，Loss:1.1135319471359253\n",
      "用时为678.2306106090546\n",
      "训练次数：6700，Loss:1.0993260145187378\n",
      "用时为681.5538456439972\n",
      "训练次数：6800，Loss:1.147373080253601\n",
      "用时为685.1776030063629\n",
      "训练次数：6900，Loss:1.086066484451294\n",
      "用时为689.139317035675\n",
      "训练次数：7000，Loss:0.9413202404975891\n",
      "整体的测试损失: 214.48090183734894\n",
      "--------第10次训练--------\n",
      "用时为696.8609638214111\n",
      "训练次数：7100，Loss:1.2167575359344482\n",
      "用时为701.2550594806671\n",
      "训练次数：7200，Loss:0.9768694043159485\n",
      "用时为704.5950481891632\n",
      "训练次数：7300，Loss:1.125922441482544\n",
      "用时为708.0238864421844\n",
      "训练次数：7400，Loss:0.8769621849060059\n",
      "用时为711.6610145568848\n",
      "训练次数：7500，Loss:1.254477858543396\n",
      "用时为715.580216884613\n",
      "训练次数：7600，Loss:1.253772497177124\n",
      "用时为719.6249239444733\n",
      "训练次数：7700，Loss:0.8575035333633423\n",
      "用时为723.7228491306305\n",
      "训练次数：7800，Loss:1.2765570878982544\n",
      "整体的测试损失: 205.35535567998886\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torchvision.transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "\n",
    "\n",
    "# 下载并加载 CIFAR-10 训练数据集\n",
    "# root 指定数据集存储的根目录；train=True 表示加载训练集；\n",
    "# transform 将数据转换为 Tensor 类型；download=True 表示如果数据集不存在则进行下载\n",
    "train_data = torchvision.datasets.CIFAR10(root= r'D:\\Desktop\\数据集', train=True, transform=torchvision.transforms.ToTensor(), download=True)\n",
    "# 下载并加载 CIFAR-10 测试数据集\n",
    "test_data = torchvision.datasets.CIFAR10(root= r'D:\\Desktop\\数据集', train=False, transform=torchvision.transforms.ToTensor(), download=True)\n",
    "\n",
    "# 计算训练集和测试集的长度\n",
    "train_data_size = len(train_data)\n",
    "test_data_size = len(test_data)\n",
    "print(f\"训练数据集的长度为: {train_data_size}\")\n",
    "print(f\"测试数据集的长度为: {test_data_size}\")\n",
    "\n",
    "# 加载数据\n",
    "# 使用 DataLoader 对训练数据进行批量加载，batch_size=64 表示每个批次包含 64 个样本\n",
    "train_dataloader = DataLoader(train_data, batch_size=64)\n",
    "# 对测试数据进行批量加载\n",
    "test_dataloader = DataLoader(test_data, batch_size=64)\n",
    "\n",
    "# 创建网络模型\n",
    "class zzy(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(zzy, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 5, 1, 2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 32, 5, 1, 2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, 5, 1, 2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 4 * 4, 64),\n",
    "            nn.Linear(64,10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "\n",
    "# 实例化自定义的网络模型 zzy（假设在 model.py 中定义）\n",
    "zzy1 = zzy()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    zzy1 = zzy1.cuda()\n",
    "# 定义损失函数\n",
    "# 使用交叉熵损失函数，常用于多分类问题\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    loss_fn = loss_fn.cuda()\n",
    "\n",
    "# 优化器创建\n",
    "# 学习率设置为 0.01\n",
    "learning_rate = 1e-2\n",
    "# 使用随机梯度下降（SGD）优化器，对 zzy1 模型的参数进行优化\n",
    "optimier = torch.optim.SGD(zzy1.parameters(), lr=learning_rate)\n",
    "\n",
    "# 设置训练网络参数\n",
    "# 记录总的训练步数\n",
    "total_train_step = 0\n",
    "# 记录总的测试步数\n",
    "total_test_step = 0\n",
    "# 训练的轮数\n",
    "epoch = 10\n",
    "\n",
    "# 添加 TensorBoard 用于可视化训练过程\n",
    "writer = SummaryWriter('log_dir')\n",
    "# 开始训练循环，共训练 epoch 轮\n",
    "start_time = time.time()\n",
    "for i in range(epoch):\n",
    "    print(f'--------第{i + 1}次训练--------')\n",
    "    # 遍历训练数据加载器中的每个批次\n",
    "    for data in train_dataloader:\n",
    "        # 从数据批次中解包图像和对应的标签\n",
    "        imgs, target = data\n",
    "        if torch.cuda.is_available():\n",
    "            imgs = imgs.cuda()\n",
    "            targets = targets.cuda()\n",
    "        # 将图像输入到模型中进行前向传播，得到模型的输出\n",
    "        outputs = zzy1(imgs)\n",
    "        # 计算模型输出与真实标签之间的损失\n",
    "        loss = loss_fn(outputs, target)\n",
    "\n",
    "        # 梯度清零，防止梯度累积\n",
    "        optimier.zero_grad()\n",
    "        # 反向传播，计算梯度\n",
    "        loss.backward()\n",
    "        # 根据计算得到的梯度更新模型的参数\n",
    "        optimier.step()\n",
    "\n",
    "        # 训练步数加 1\n",
    "        total_train_step += 1\n",
    "        # 每训练 100 步，打印一次训练信息并将训练损失写入 TensorBoard\n",
    "        if total_train_step % 100 == 0:\n",
    "            end_time =time.time()\n",
    "            print(f'用时为{end_time-start_time}')\n",
    "            print(f'训练次数：{total_train_step}，Loss:{loss.item()}')\n",
    "            # 将训练损失添加到 TensorBoard 中，用于后续可视化\n",
    "            writer.add_scalar('train_loss', loss.item(), total_train_step)\n",
    "\n",
    "    # 测试步骤开始\n",
    "    # 初始化总的测试损失为 0\n",
    "    total_test_loss = 0\n",
    "    # 上下文管理器，在测试过程中不进行梯度计算，减少内存消耗\n",
    "    with torch.no_grad():\n",
    "        # 遍历测试数据加载器中的每个批次\n",
    "        for data in test_dataloader:\n",
    "            # 从数据批次中解包图像和对应的标签\n",
    "            imgs, targets = data\n",
    "            if torch.cuda.is_available():\n",
    "                imgs = imgs.cuda()\n",
    "                targets = targets.cuda()\n",
    "            # 将图像输入到模型中进行前向传播，得到模型的输出\n",
    "            outputs = zzy1(imgs)\n",
    "            # 计算模型输出与真实标签之间的损失\n",
    "            loss = loss_fn(outputs, targets)\n",
    "            # 累加测试损失\n",
    "            total_test_loss += loss.item()\n",
    "    # 这里存在错误，应该打印整体的测试损失，而不是 total_test_step\n",
    "    print(f'整体的测试损失: {total_test_loss}')\n",
    "    # 将测试损失添加到 TensorBoard 中，用于后续可视化\n",
    "    writer.add_scalar('test_loss', total_test_loss, total_test_step)\n",
    "    # 测试步数加 1\n",
    "    total_test_step += 1\n",
    "\n",
    "# 关闭 SummaryWriter，释放资源\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
